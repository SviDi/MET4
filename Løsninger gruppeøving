# -- LØSNINGSFORSLAG TIL DATAØVING 1 -- #
# ------          MET4           ------ #


# les inn data
library(readxl)
violence <- read_excel("violence.xlsx")

# utforsking av datastruktur
class(violence)
dim(violence)
names(violence)
str(violence)
head(violence)

# Vektorer med aggresjonsnivå til gruppen som har spilt voldelig/ikke-voldelig spill 
voldelig      <- violence$aggression_level[violence$violent_treatment == "Violent"]      
ikke_voldelig <- violence$aggression_level[violence$violent_treatment == "Less Violent"]

# Deskriptiv statistikk
min(voldelig)
mean(voldelig)
sd(voldelig)
length(voldelig)
summary(voldelig) 
#... osv

# Vi ser at vi har litt færre observasjoner i vårt datasett enn det som
# er oppgitt i oppgaven. Derfor blir f.eks. gjennomsnittet litt annerledes.
# Dette skyldes for øvrig at noen forsøkspersoner mangler data på en annen
# variabel som vi skal bruke senere i oppgaven, så de er tatt ut her.


# Skalert histogram
hist(voldelig, freq = TRUE, breaks = 10, main = "Voldelig")
hist(ikke_voldelig, freq = TRUE, breaks = 10, main = "Ikke voldelig")

# boxplot
boxplot(voldelig, ikke_voldelig, names = c("voldelig", "ikke voldelig"))

# Fordelingen av aggresjonsscore ser nesten helt identisk ut i de to gruppene.
# Det er vanskelig å tenke at de skal være trukket fra to fordelinger som er
# veldig ulike.




# -- L?SNINGSFORSLAG TIL DATA?VING 2 -- #
# ------          MET4           ------ #


# OPPGAVE 1 ---------

# Sp?rsm?l 1.1: Leser inn datasettet
library(readxl)                                
data <- read_excel("ovelsesdata.xlsx")    

# Sp?rsm?l 1.2: Er forventet avling st?rre ved bruk av nye spr?ytemidler?
mu0 <- 100    # Forventet avling ved bruk av gammel metode
t.test(x = data$X2, alternative = "greater", mu = mu0)

# Vi f?r en p-verdi p? 0.038, dvs at vi forkaster nullhypotesen om at forventet
# avling er lik 100 med den nye metoden.

# Sp?rsm?l 1.3: Har variansen forandret seg?
sigma_0   <- 10                  # Nullhypotesen
st.avvik  <- sd(data$X2)         # Det empiriske standardavviket
n         <- length(data$X2)     # Antall observasjoner

T <- (n-1)*st.avvik^2/sigma_0^2  # Testobservatoren

# Kritiske verdier
L <- qchisq(0.025, df = n - 1)
U <- qchisq(0.975, df = n - 1)

# Testobservatoren ligger over nedre forkastningsgrense og under ?vre
# forkastningsgrense, s? vi forkaster ikke nullhypotesen om at den sanne
# variansen fortsatt er lik 10.

# Sp?rsm?l 1.4: To to-utvalgs t-tester, med og uten paring. Antar lik varians,
# ref forrige oppgave.
t.test(x = data$X1, y = data$X2, var.equal = TRUE)
t.test(x = data$X1, y = data$X2, var.equal = TRUE, paired = TRUE)

# Vi f?r ikke forkastning i den f?rste testen, men n?r vi parer observasjonene
# tar vi h?yde for at det kan v?re variasjoner mellom jordlappene (f.eks pga
# jordsmonn eller lysforhold), og da ser vi en klar forskjell mellom avlingen
# med de to spr?ytemetodene. Det kan dog hende at noe av forskjellen kan oppst?
# p? grunn av forskjeller i v?r/temparatur mellom de to vekstsesongene, men det
# kan vi ikke unders?ke ved hjelp av dette datasettet.

# OPPGAVE 2 --------

# Sp?rsm?l 2.1: Les inn datasettet
violence <- read_excel("violence.xlsx")

# Sp?rsm?l 2.2: Henter ut vektorer
voldelig      <- violence$aggression_level[violence$violent_treatment == "Violent"]
ikke_voldelig <- violence$aggression_level[violence$violent_treatment == "Less Violent"]

# Sp?rsm?l 2.3: Kj?rer en t-test for to populasjoner. Ingen spesiell grunn til ?
# velge ensidig test, og standardavvikene er s? like at vi antar lik varians i
# testen. Dette kan vi selvsagt ogs? teste for mer formelt ved hjelp av en
# varianstest.
t.test(voldelig, ikke_voldelig, var.equal = TRUE)

# Ingen forkastning, ikke overrskende med tanke p? boksplottet vi lagde i
# forrige ?ving.

# Oppgave 2.4: Lager et redusert datasett og krysstabell
violence_redusert <- violence[c("violent_treatment", "experienced_violence")]
krysstabell <- table(violence_redusert)

chisq.test(krysstabell)

# Mega-soleklar forkastning, som p? ingen m?te er overraskende, og det skulle da
# bare mangle.

# OPPGAVE 3 ------

# Sp?rsm?l 3.1: Leser inn datasettet
yield <- read_excel("roubik_2002_coffe_yield.xlsx")

# Sp?rsm?l 3.2: Trekker ut de fire vektorene
new_p1 <- yield$yield_61_to_80[yield$world == "new"]
new_p2 <- yield$yield_81_to_01[yield$world == "new"]
old_p1 <- yield$yield_61_to_80[yield$world == "old"]
old_p2 <- yield$yield_81_to_01[yield$world == "old"]

# Sp?rsm?l 3.3: En paret t-test for ? unders?ke om avlingen har endret seg i den
# gamle verden:
t.test(old_p1, old_p2, paired = TRUE)

# Sp?rsm?l 3.4: En paret t-test for ? unders?ke om avlingen har endret seg i den
# nye verden:
t.test(new_p1, new_p2, paired = TRUE)


# Sp?rsm?l 3.5.
#
# For det f?rste er det langt igjen til vi kan gjennomf?re en kausal fortolkning
# av resultatet (er flere bier er *?rsaken* til st?rre avling?). Til det trenger
# vi helst et kontrollert og randomisert eksperiment der vi lar bier pollinere
# et sett med planter, og dekker til en kontrollgruppe slik at eneste
# forskjellen er at insekter ikke kommer til. Forfatteren av den aktuelle
# artikkelen er fors?vidt inne p? dette tankesporet, og viser til at slike
# eksperimenter har blitt gjort.
#
# Den andre innvendingen er litt mer subtil, men desto viktigere ? f? ?ye p?.
# Det at ?kningen i den gamle verden ikke er signifikant, men ?kningen i den nye
# verden er signifikant, betyr *IKKE* at forskjellen mellom den gamle og den nye
# verden er signifikant!!! Det m? testes for seg selv, og lar seg enklest gj?re
# ved ? teste om gjennomsnittet av differansene mellom de to periodene i den nye
# verden er signifikant forskjellig fra gjennomsnittet av differansene mellom de
# to periodene i den gamle verden.
#
# Bruk gjerne litt tid p? ? akseptere dette argumentet. Testen gj?r vi enkelt
# som f?lger:

t.test(new_p2 - new_p1, old_p2 - old_p1)

# Og den testen forkaster ikke nullhypotesen om lik utvikling over tid! F?lgende
# bloggpost diskuterer dette eksempelet, men i lys av en litt annen statistisk
# estimeringsteknikk:
#
# http://www.sumsar.net/blog/2014/02/bayesian-first-aid-two-sample-t-test/
#



# -- L?SNINGSFORSLAG TIL DATA?VING 3 -- #
# ------           MET4          ------ #


# OPPGAVE 2.2 ---------
library(readxl)
visits <- read_excel("C16-01.xlsx")

# OPPGAVE 2.3 ---------
plot(visits$Week, visits$Museum, type = "l")
lines(visits$Week, visits$`A-Park`)

# OPPGAVE 2.4 ---------
plot(visits$Week, 
     visits$Museum, 
     type = "l",
     col = "darkred",
     xlab = "Ukenummer",
     ylab = "Bes?kstall",
     main = "Bes?kstall p? museet og forn?yelsesparken")
lines(visits$Week, visits$`A-Park`)

# OPPGAAVE 2.5 ---------
reg1 <- lm(Museum ~ `A-Park`, data = visits, subset = 1:32)

# OPPGAVE 2.6 ----------
library(stargazer)
stargazer(reg1, type = "text")

# Oppgave 2.7 ----------
plot(reg1$residuals,
     xalb = "",
     ylab = "",
     main = "Residualer mot indeks",
     pch = 20,
     bty = "l")
abline(h = 0, lty = 2)

qqnorm(reg1$residuals,
       main = "QQ-plot",
       pch = 20,
       bty = "l")
qqline(reg1$residuals, lty = 2)

hist(reg1$residuals,
     col = "grey30",
     border = "white",
     main = "Histogram over residualer",
     xlab = "",
     ylab = "")

# Det ser ikke ut til ? v?re dramatiske avvik fra antakelsene i dette tilfellet.
# Ingen spesielle m?nster i  residualplotter, og heller ingen p?fallende avvik
# fra normalitet.

# OPPGAVE 2.8 ----------
uker_stengt <- visits$Museum == 0
visits_pred <- visits[uker_stengt, "A-Park"]
predicted_visits1 <- predict(reg1, newdata = visits_pred)

# OPPGAVE 2.9 ----------
plot(visits$Week, 
     visits$Museum, 
     type = "l",
     col = "darkred",
     xlab = "Ukenummer",
     ylab = "Bes?kstall",
     main = "Bes?kstall p? museet og forn?yelsesparken")
lines(visits$Week, visits$`A-Park`)
lines(visits$Week[uker_stengt], 
      predicted_visits1, 
      lty = 2, 
      col = "darkblue")

# OPPGAVE 2.10 ---------

# Vi ser fra figuren at bes?kstallet p? museet f?r brannen l? litt under
# bes?kstallet i forn?yelsesparken. Det ser vi igjen i de estimerte
# regresjonskoeffisientene, der det kommer frem at vi skal sette det hypotetiske
# bes?kstallet til museet i gjenoppbyggingsperioden til dr?yt 70% av
# bes?kstallet i forn?yelsesparken. Konstantleddet er forholdsvis lite og ikke
# signifikant forskjellig fra null. Dette ser vi igjen i figuren vi lagde i
# forrige oppgave.

# OPPGAVE 2.11 ---------
reg2 <- lm(Museum ~ `A-Park`, data = visits, subset = 180:205)
summary(reg2)

# OPPGAVE 2.12 ---------
predicted_visits2 <- predict(reg2, newdata = visits_pred)
plot(visits$Week, 
     visits$Museum, 
     type = "l",
     col = "darkred",
     xlab = "Ukenummer",
     ylab = "Bes?kstall",
     main = "Bes?kstall p? museet og forn?yelsesparken")
lines(visits$Week, visits$`A-Park`)
lines(visits$Week[uker_stengt], 
      predicted_visits1, 
      lty = 2, 
      col = "darkblue")
lines(visits$Week[uker_stengt], 
      predicted_visits2, 
      lty = 2, 
      col = "forestgreen")

# OPPGAVE 2.13 --------
sum(6.99*(predicted_visits2 - predcted_visits1))

# OPPGAVE 2.14 -------- 

# Det er ingenting i veien for ? bruke *b?de* perioden f?r brannen og perioden
# etter brannen til ? estimere regresjonsmodellen, da blir begge syn tatt hensyn
# til, og vektet noenlunde likt siden det er omtrent like mange observasjoner i
# de to gruppene. Bruk f.eks "subset = c(1:32, 180:205)" for ? f? det til.
# Alternativt gj?r vi det enkelt og bare m?tes p? midten. Begge har litt feil,
# og begge har litt rett.
#
# Et annet moment som kan komme inn her (takk til stud.ass. H?vard for
# innspill!) er at det ny?pnede museet er betraktelig st?rre enn det som brant
# ned, og at det kan ha v?rt med p? ? ?ke populariteten (og kanskje forklare den
# helt og fullt). Forsikringsselskapet kan da argumentere med at de har
# forsikret museet slik det stod da det brant, og ikke kan ta hensyn til en
# eventuell oppgradering som museet *kanskje* ville gjort uansett.
¨
# bloggpost diskuterer dette eksempelet, men i lys av en litt annen statistis


# -- LØSNINGSFORSLAG TIL DATAØVING 4 -- #
# ------          MET4           ------ #


# Dataene får vi tak i via pakken ISLR
library(ISLR)       
head(Default)       # Ta en titt på dataene

# Boksplott som indikerer sammenhengen mellom å ikke betale kreditkortgjeld og størrelsen på gjelden
boxplot(balance ~ default, data = Default,
        ylab = "balance", xlab = "default")


# Vi deler dataene inn i et treningsett og et testsett
library(dplyr)
my_data <- Default %>%
  mutate(id = row_number()) # først legger vi til en unik id variabel til hvert individ

set.seed(123)               # Fiks "tilfeldig frø" sikrer at du kan trekke det samme treningssettet om igjen
train <- my_data %>%        # Så trekker vi et utvalg bestående av 70 % av dataene
  sample_frac(.70)

test <- my_data %>%         # Treningssettet er da de resterende 30 % av dataene
  anti_join(train, by = 'id')

# model1: Logistisk regresjon med  'balance' (gjeld) som forklaringsvariabel
model1 <- glm(default ~ balance, data = train,
              family = "binomial")
summary(model1)
exp(coef(model1))

# Prediksjon av sannsynlighet for mislighold for to personer med 1000 og 2000 kr i 'balance' (gjeld)
pred <- predict(model1, data.frame(balance = c(1000, 2000)), type = "response")
ifelse(pred > 0.5, "Yes", "No")


# model2: logistisk regresjon med 'student' som forklaringsvariabel
model2 <- glm(default ~ student, family = "binomial", data = train)
summary(model2)
exp(coef(model2))

# Prediksjon av sannsynlighet for mislighold for en student og en ikke-student
predict(model2, data.frame(student = factor(c("Yes", "No"))), type = "response")
# En student har større sannsynlighet for mislighold

# model3: multippel logistisk regresjon med alle forklaringsvariablene
model3 <- glm(default ~ balance + income + student, family = "binomial", data = train)
summary(model3) 

# # Prediksjon av sannsynlighet for mislighold for en student og en ikke-student med lik gjeld og inntekt
to_kunder <- data.frame(balance = 1500, income = 10000, student = c("Yes", "No"))
predict(model3, newdata = to_kunder, type = "response") 

# Ikke-studenten har dobbelt så stor sannsynlighet for mislighold. Dette samsvarer jo ikke med model2! 
# Når vi har justert for gjeld og inntekt så viser det seg at studenter håndterer lånet sitt bedre 
# enn ikke-studenter. Dette er et eksempel på kolineæritet mellom forklaringsvariablene. Det viser 
# seg at det å være student og gjeld er avhengige variabler. Vi ser det ut fra følgende boksplott

# boksplot
boxplot(balance ~ student, data = train, 
        names = c("ikke-student", "student"),
        ylab = "gjeld")

# Moral: Er du banken og skal vurdere om en person skal få lån eller ikke tenker du som følger:
# 1) Hvis ikke du vet hvilken gjeld personen har er en student mer risikabel enn en ikke-student.
#    Dette er fordi studenter i gjennomsnitt har større gjeld.
# 2) Hvis du vet hvilken gjeld personen har, vil en student være mindre risikabel enn en ikke-student 
#    med en tilsvarende gjeld.



#---------k nærmeste naboer klassifisering
library(caret)

# R-kode dersom vi vil velge k automatisk
set.seed(200)
trControl <- trainControl(method  = "cv", # 5-fold kryssvalidering
                          number  = 5)

# Tilpasser modellen
model4 <- train(default ~ balance + income + student,
                 data = train,
                 method = "knn",
                 trControl  = trControl,
                 metric     = "Accuracy")

# Hvilken k valgte kryssvalideringen?
k <- model4$finalModel$k
k
  
# prediksjon av to kunder 

predict(model4, newdata = to_kunder)

#--------- test av klassifiseringsevne

# logistisk regresjonsmodell
sann <- test$default                                              # Den sanne verdien i testdataene

pred_logreg <- predict(model3, newdata = test, type = "response") # Predikert sannsynlighet
klass_logreg <- ifelse(pred_logreg > 0.5, "Yes", "No")            # Klassifisering av kundene
logreg_tab <- table(sann, klass_logreg)                           # Kontigenstabell
logreg_tab_norm <- logreg_tab %>% 
  prop.table %>%
  round(3)

logreg_tot <- sum(diag(logreg_tab_norm))               # Total andel korrekt klassfisering

# knn 
knn_klass <- predict(model4, newdata = test)   # Prediksjon av test data
knn_tab <- table(sann, knn_klass)               # kontigenstabell
knn_tab_norm <- knn_tab %>%                     # Normalisert kontigenstabell
  prop.table %>%
  round(3)
knn_tab_norm
knn_tot <- sum(diag(knn_tab_norm))               # Total andel korrekt klassfisering

knn_tot
logreg_tot

# Vi ser at den logistiske regresjonsmodellen totalt sett gjør det bedre og spesielt når det kommer til å
# predikere de som misligholder. Dermed gjør den mindre såkalte falske positiv feil noe som er viktig for banken
# dersom den ønsker å luke ut dårlige kunder som misligholder. 
# knn gjør det litt bedre i å spå hvem som ikke misligholder og gjør dermed ferre "falske positive" feil
# men dette er mindre alvorlig for banken hvis den er konservativ (dog vil de akseptere flere "gode" kunder)





#----- Ekstra stilige figurer med ggplot2 (ikke del av øvingen, men illuster litt bedre hva som skjer)----#
library(ggplot2)

# Showcasing why ordinary linear regression does not work
my_data %>%
  mutate(prob = ifelse(default == "Yes", 1, 0)) %>%
  ggplot(aes(balance, prob)) +
  geom_point(alpha = .15) +
  geom_smooth(method = "lm") +
  ggtitle("Linear regression model fit") +
  xlab("Balance") +
  ylab("Probability of Default")

# Plot of model
my_data %>%
  mutate(prob = ifelse(default == "Yes", 1, 0)) %>%
  ggplot(aes(balance, prob)) +
  geom_point(alpha = .15) +
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  ggtitle("Logistic regression model fit") +
  xlab("Balance") +
  ylab("Probability of Default")

# Figure illustrating whats going on
ggplot(default, aes(x = student, y = balance)) + 
  geom_boxplot(aes(color = student))

# Regression curve adjusted for students and non-students:
my_data %>%
  mutate(prob = ifelse(default == "Yes", 1, 0)) %>%
  ggplot(aes(balance, prob, color = student)) +
  geom_point(alpha = .15) +
  geom_smooth(aes(color = student), method = "glm", method.args = list(family = "binomial")) +
  ggtitle("Logistic regression model fit") +
  xlab("Balance") +
  ylab("Probability of Default")

